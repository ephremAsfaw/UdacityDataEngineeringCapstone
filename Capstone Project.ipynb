{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "In our research company, Data Scientists are tasked to observe tourism behaviors and called on the Data Engineers to clean, process and develop data model (star schema) that would be the starting point of long-term project (of more data collection and experimenting) that will allow them to hypothesis relationships or patterns between the cities that non-immigrants visited and the cities demographics. \n",
    "We will create dimensional (and fact) tables and saved as parquet files for star schema model on I94 non-immigrants ports of entires data and US port city demographics data which will be a data model for queries on non-immigrants entering US to observe relationships between non-immigrants profiles (age, country of origin, seasons or holidays visited, reason for visiting, etc) and the cities demographics. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    ".getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import first\n",
    "from pyspark.sql.functions import upper, col\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType\n",
    "from pyspark.sql.functions import udf, date_format\n",
    "import datetime as dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc.\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included?\n",
    "\n",
    "##### The I94 immigration data comes from the US National Tourism and Trade Office. This data was already provided inside sas_data folder in parquet file type. We will use the following records:\n",
    "\n",
    "1) i94Bir - Age of non-immigrant in years\n",
    "\n",
    "2) admnum - Admission Number\n",
    "\n",
    "3) i94res - 3 digit code of nationality\n",
    "\n",
    "4) i94port - 3 character code of destination USA city\n",
    "\n",
    "5) arrdate - arrival date in the USA (SAS date numeric field)\n",
    "\n",
    "6) i94mode - 1 digit mode (plane, boat, etc) of travel code\n",
    "\n",
    "7) i94visa - reason for immigration\n",
    "\n",
    "8) gender - Non-immigrant sex\n",
    "\n",
    "9) depdate - departure date in the USA (SAS date numeric field)\n",
    "\n",
    "10) count - Used for summary statistics \n",
    "\n",
    "##### U.S. City Demographic Data comes from OpenSoft in csv file format and will be converted to json. We will use the following records:\n",
    "\n",
    "1) City (USA)\n",
    "\n",
    "2) Male Population\n",
    "\n",
    "3) Female Population\n",
    "\n",
    "4) Median Age (overall median age within the city population)\n",
    "\n",
    "5) Total Population\n",
    "\n",
    "6) Foreign-Born (number of foreign born residences)\n",
    "\n",
    "7) State Code (USA state abbreviation of the City column)\n",
    "\n",
    "8) Race (specifies race category suchas Asian, Alaskan Indian, Black, Hispanic, etc)\n",
    "\n",
    "9) Count (number of people under specific race category anotated by Race column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### US CITIES DEMOGRAPHICS DATA SET (CLEANING AND TRANSFORMATION)\n",
    "We need to Transform the US Demo dataset because it contains duplicate columns.\n",
    "We need to pivot the Race column to convert Race categories into individual columns.\n",
    "We first separate the US demo dataset into two datasets from both Race and Count columns. \n",
    "We will have two datasets (`US` and `US RACE COUNT`). `US RACE COUNT` dataset will also include \n",
    "City and State Code columns so we can use them to join back both datasets after we first \n",
    "remove duplicate rows from the `US` dataset and pivot the `US Race Count` dataset. In theory both\n",
    "datasets should have equal rows to join them back to original transformed state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read US Cities Demo dataset file\n",
    "us_spark=spark.read.csv(\"./data/us-cities-demographics.csv\", sep=';', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State',\n",
       " 'Median Age',\n",
       " 'Male Population',\n",
       " 'Female Population',\n",
       " 'Total Population',\n",
       " 'Number of Veterans',\n",
       " 'Foreign-born',\n",
       " 'Average Household Size',\n",
       " 'State Code',\n",
       " 'Race',\n",
       " 'Count']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check columns of dataset\n",
    "us_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+---------------+-----------------+----------------+------------+----------------------+\n",
      "|   City|     state|Median Age|male population|female population|total population|foreign-born|Average Household Size|\n",
      "+-------+----------+----------+---------------+-----------------+----------------+------------+----------------------+\n",
      "|Abilene|     Texas|      31.3|          65212|            60664|          125876|        8129|                  2.64|\n",
      "|Abilene|     Texas|      31.3|          65212|            60664|          125876|        8129|                  2.64|\n",
      "|Abilene|     Texas|      31.3|          65212|            60664|          125876|        8129|                  2.64|\n",
      "|Abilene|     Texas|      31.3|          65212|            60664|          125876|        8129|                  2.64|\n",
      "|Abilene|     Texas|      31.3|          65212|            60664|          125876|        8129|                  2.64|\n",
      "|  Akron|      Ohio|      38.1|          96886|           100667|          197553|       10024|                  2.24|\n",
      "|  Akron|      Ohio|      38.1|          96886|           100667|          197553|       10024|                  2.24|\n",
      "|  Akron|      Ohio|      38.1|          96886|           100667|          197553|       10024|                  2.24|\n",
      "|  Akron|      Ohio|      38.1|          96886|           100667|          197553|       10024|                  2.24|\n",
      "|  Akron|      Ohio|      38.1|          96886|           100667|          197553|       10024|                  2.24|\n",
      "|Alafaya|   Florida|      33.5|          39504|            45760|           85264|       15842|                  2.94|\n",
      "|Alafaya|   Florida|      33.5|          39504|            45760|           85264|       15842|                  2.94|\n",
      "|Alafaya|   Florida|      33.5|          39504|            45760|           85264|       15842|                  2.94|\n",
      "|Alafaya|   Florida|      33.5|          39504|            45760|           85264|       15842|                  2.94|\n",
      "|Alameda|California|      41.4|          37747|            40867|           78614|       18841|                  2.52|\n",
      "|Alameda|California|      41.4|          37747|            40867|           78614|       18841|                  2.52|\n",
      "|Alameda|California|      41.4|          37747|            40867|           78614|       18841|                  2.52|\n",
      "|Alameda|California|      41.4|          37747|            40867|           78614|       18841|                  2.52|\n",
      "|Alameda|California|      41.4|          37747|            40867|           78614|       18841|                  2.52|\n",
      "| Albany|  New York|      32.8|          47627|            50825|           98452|       11948|                  2.08|\n",
      "+-------+----------+----------+---------------+-----------------+----------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check us_spark dataset for duplicate rows and which columns cause the duplicates\n",
    "us_spark.select(\"City\",\"state\",\"Median Age\",\"male population\",\"female population\",\"total population\", \\\n",
    "                  \"foreign-born\",\"Average Household Size\").orderBy(\"city\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------------------+------+\n",
      "|   city|state code|                Race| count|\n",
      "+-------+----------+--------------------+------+\n",
      "|Abilene|        TX|American Indian a...|  1813|\n",
      "|Abilene|        TX|  Hispanic or Latino| 33222|\n",
      "|Abilene|        TX|               White| 95487|\n",
      "|Abilene|        TX|               Asian|  2929|\n",
      "|Abilene|        TX|Black or African-...| 14449|\n",
      "|  Akron|        OH|               White|129192|\n",
      "|  Akron|        OH|  Hispanic or Latino|  3684|\n",
      "|  Akron|        OH|Black or African-...| 66551|\n",
      "|  Akron|        OH|               Asian|  9033|\n",
      "|  Akron|        OH|American Indian a...|  1845|\n",
      "|Alafaya|        FL|  Hispanic or Latino| 34897|\n",
      "|Alafaya|        FL|               Asian| 10336|\n",
      "|Alafaya|        FL|               White| 63666|\n",
      "|Alafaya|        FL|Black or African-...|  6577|\n",
      "|Alameda|        CA|               White| 44232|\n",
      "|Alameda|        CA|American Indian a...|  1329|\n",
      "|Alameda|        CA|Black or African-...|  7364|\n",
      "|Alameda|        CA|  Hispanic or Latino|  8265|\n",
      "|Alameda|        CA|               Asian| 27984|\n",
      "| Albany|        NY|  Hispanic or Latino|  9368|\n",
      "+-------+----------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check subset of `US` dataset that maybe causing dupliate rows\n",
    "us_spark.select(\"city\",\"state code\",\"Race\",\"count\").orderBy(\"city\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start transformation for US CITIES DEMOGRAPHICS DATA SET:\n",
    "*CLEANING DATA SET SUMMARY NOTED BY STEPS:*\n",
    "1. 'Race' and 'Count' records are causing duplicate rows.\n",
    "    We will separate them from US demographics data set and include 'City' and 'State Code'.\n",
    "2. 'Race' will be pivoted to column headers and saved to us_race_cnt dataset\n",
    "3. US dataset will be cleaned of duplicate rows (shown above).\n",
    "4. Cleaned US dataset will be joined back with us_race_cnt dataset\n",
    "to eventually have unique rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating 'us_race_cnt' dataset\n",
    "us_race_cnt=(us_spark.select(\"city\",\"state code\",\"Race\",\"count\")\n",
    "    .groupby(us_spark.City, \"state code\")\n",
    "    .pivot(\"Race\")\n",
    "    .agg(first(\"Count\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|        City|state code|American Indian and Alaska Native|Asian|Black or African-American|Hispanic or Latino| White|\n",
      "+------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|     Abilene|        TX|                             1813| 2929|                    14449|             33222| 95487|\n",
      "|       Akron|        OH|                             1845| 9033|                    66551|              3684|129192|\n",
      "|     Alafaya|        FL|                             null|10336|                     6577|             34897| 63666|\n",
      "|     Alameda|        CA|                             1329|27984|                     7364|              8265| 44232|\n",
      "|      Albany|        NY|                             1611| 8090|                    31303|              9368| 58368|\n",
      "|      Albany|        GA|                              445|  650|                    53440|              1783| 17160|\n",
      "| Albuquerque|        NM|                            32243|25140|                    26774|            271854|411847|\n",
      "|  Alexandria|        VA|                             1133|13315|                    37168|             25573|106215|\n",
      "|    Alhambra|        CA|                              687|44067|                     1905|             31386| 20811|\n",
      "|       Allen|        TX|                              227|15790|                    13140|             10615| 69840|\n",
      "|       Allen|        PA|                             1076| 2670|                    22304|             59176| 74187|\n",
      "|    Amarillo|        TX|                             4260| 8563|                    14050|             65392|174214|\n",
      "|        Ames|        IA|                             null| 8979|                     1103|              2024| 56157|\n",
      "|     Anaheim|        CA|                             2489|53270|                     9775|            201593|259820|\n",
      "|   Anchorage|        AK|                            36339|36825|                    23107|             27261|212696|\n",
      "|   Ann Arbor|        MI|                             1935|18797|                     9577|              5888| 90173|\n",
      "|     Antioch|        CA|                             3462|14333|                    23227|             35563| 51151|\n",
      "|Apple Valley|        CA|                             1446| 2281|                     9124|             25928| 60767|\n",
      "|    Appleton|        WI|                              835| 5561|                     3407|              5139| 64674|\n",
      "|Arden-Arcade|        CA|                             2587| 7355|                    13647|             15273| 69369|\n",
      "+------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking dataset\n",
    "us_race_cnt.orderBy(\"city\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(596, 596)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing both datasets after dropping duplicate rows\n",
    "(us_race_cnt.count(), us_race_cnt.dropDuplicates().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uscols=[\"Number of Veterans\",\"Race\",\"Count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we don't need and drop duplicate rows\n",
    "us=us_spark.drop(*uscols).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2891, 596)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing row count between original and new dataset with dropped duplicate rows\n",
    "(us_spark.count(), us.count())\n",
    "# We can see that new cleaned 'us' dataset now matches number of rows with 'us_race_cnt' dataset\n",
    "# which will be joined together into one 'us' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of records after joining both data sets\n",
    "us.join(us_race_cnt, [\"city\",\"state code\"]).count()\n",
    "# We now see total rows match both datasets after joining them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+------------+----------+---------------+-----------------+----------------+------------+----------------------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|        City|State Code|       State|Median Age|Male Population|Female Population|Total Population|Foreign-born|Average Household Size|American Indian and Alaska Native|Asian|Black or African-American|Hispanic or Latino| White|\n",
      "+------------+----------+------------+----------+---------------+-----------------+----------------+------------+----------------------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|     Abilene|        TX|       Texas|      31.3|          65212|            60664|          125876|        8129|                  2.64|                             1813| 2929|                    14449|             33222| 95487|\n",
      "|       Akron|        OH|        Ohio|      38.1|          96886|           100667|          197553|       10024|                  2.24|                             1845| 9033|                    66551|              3684|129192|\n",
      "|     Alafaya|        FL|     Florida|      33.5|          39504|            45760|           85264|       15842|                  2.94|                             null|10336|                     6577|             34897| 63666|\n",
      "|     Alameda|        CA|  California|      41.4|          37747|            40867|           78614|       18841|                  2.52|                             1329|27984|                     7364|              8265| 44232|\n",
      "|      Albany|        NY|    New York|      32.8|          47627|            50825|           98452|       11948|                  2.08|                             1611| 8090|                    31303|              9368| 58368|\n",
      "|      Albany|        GA|     Georgia|      33.3|          31695|            39414|           71109|         861|                  2.38|                              445|  650|                    53440|              1783| 17160|\n",
      "| Albuquerque|        NM|  New Mexico|      36.0|         273323|           285808|          559131|       58200|                  2.49|                            32243|25140|                    26774|            271854|411847|\n",
      "|  Alexandria|        VA|    Virginia|      36.6|          74989|            78522|          153511|       44030|                   2.2|                             1133|13315|                    37168|             25573|106215|\n",
      "|    Alhambra|        CA|  California|      41.0|          42184|            43388|           85572|       44441|                  2.89|                              687|44067|                     1905|             31386| 20811|\n",
      "|       Allen|        TX|       Texas|      37.2|          51324|            46814|           98138|       19649|                  3.04|                              227|15790|                    13140|             10615| 69840|\n",
      "|       Allen|        PA|Pennsylvania|      33.5|          60626|            59581|          120207|       19652|                  2.67|                             1076| 2670|                    22304|             59176| 74187|\n",
      "|    Amarillo|        TX|       Texas|      33.8|          99391|           100260|          199651|       21124|                  2.64|                             4260| 8563|                    14050|             65392|174214|\n",
      "|        Ames|        IA|        Iowa|      23.0|          33814|            31238|           65052|        8606|                  2.16|                             null| 8979|                     1103|              2024| 56157|\n",
      "|     Anaheim|        CA|  California|      33.6|         179603|           171135|          350738|      137133|                  3.45|                             2489|53270|                     9775|            201593|259820|\n",
      "|   Anchorage|        AK|      Alaska|      32.2|         152945|           145750|          298695|       33258|                  2.77|                            36339|36825|                    23107|             27261|212696|\n",
      "|   Ann Arbor|        MI|    Michigan|      28.1|          58789|            58281|          117070|       20717|                  2.17|                             1935|18797|                     9577|              5888| 90173|\n",
      "|     Antioch|        CA|  California|      34.0|          54733|            55809|          110542|       24942|                  3.31|                             3462|14333|                    23227|             35563| 51151|\n",
      "|Apple Valley|        CA|  California|      34.3|          32873|            39312|           72185|        5801|                  3.03|                             1446| 2281|                     9124|             25928| 60767|\n",
      "|    Appleton|        WI|   Wisconsin|      35.6|          37217|            38038|           75255|        4454|                  2.49|                              835| 5561|                     3407|              5139| 64674|\n",
      "|Arden-Arcade|        CA|  California|      41.5|          47596|            48680|           96276|       13458|                  2.18|                             2587| 7355|                    13647|             15273| 69369|\n",
      "+------------+----------+------------+----------+---------------+-----------------+----------------+------------+----------------------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking data sample\n",
    "us.join(us_race_cnt, [\"city\",\"state code\"]).orderBy(\"city\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally saving (committing) joined US dataset\n",
    "us=us.join(us_race_cnt, [\"city\",\"state code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+-----------+----------+---------------+-----------------+----------------+------------+----------------------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|           City|State Code|      State|Median Age|Male Population|Female Population|Total Population|Foreign-born|Average Household Size|American Indian and Alaska Native|Asian|Black or African-American|Hispanic or Latino| White|\n",
      "+---------------+----------+-----------+----------+---------------+-----------------+----------------+------------+----------------------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|Highlands Ranch|        CO|   Colorado|      39.6|          49186|            53281|          102467|        8827|                  2.72|                             1480| 5650|                     1779|              8393| 94499|\n",
      "|           Kent|        WA| Washington|      33.4|          61825|            65137|          126962|       38175|                  3.06|                             3651|26168|                    20450|             21928| 67918|\n",
      "|        Madison|        WI|  Wisconsin|      30.7|         122596|           126360|          248956|       30090|                  2.23|                             2296|23937|                    20424|             19697|204302|\n",
      "|         Denver|        CO|   Colorado|      34.1|         341137|           341408|          682545|      113222|                  2.33|                            14008|32491|                    72288|            207847|546370|\n",
      "|         Caguas|        PR|Puerto Rico|      40.4|          34743|            42265|           77008|        null|                  null|                              624| null|                     null|             76349|  null|\n",
      "+---------------+----------+-----------+----------+---------------+-----------------+----------------+------------+----------------------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(596, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another check\n",
    "(us.count(), us.show(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change `state code` column name to `state_code` and other similar problems to avoid parquet complications\n",
    "us=us.select('City', col('State Code').alias('State_Code'), 'State', col('Median Age').alias('Median_age'),\n",
    "     col('Male Population').alias('Male_Pop'), col('Female Population').alias('Fem_Pop'), \n",
    "        col('Total Population').alias('Ttl_Pop'), 'Foreign-born', \n",
    "          col('Average Household Size').alias('Avg_Household_Size'),\n",
    "             col('American Indian and Alaska Native').alias('Native_Pop'), \n",
    "                 col('Asian').alias('Asian_Pop'), \n",
    "                    col('Black or African-American').alias('Black_Pop'), \n",
    "                      col('Hispanic or Latino').alias('Latino_Pop'), \n",
    "                        col('White').alias('White_Pop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+\n",
      "|           City|State_Code|     State|Median_age|Male_Pop|Fem_Pop|Ttl_Pop|Foreign-born|Avg_Household_Size|Native_Pop|Asian_Pop|Black_Pop|Latino_Pop|White_Pop|\n",
      "+---------------+----------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+\n",
      "|Highlands Ranch|        CO|  Colorado|      39.6|   49186|  53281| 102467|        8827|              2.72|      1480|     5650|     1779|      8393|    94499|\n",
      "|           Kent|        WA|Washington|      33.4|   61825|  65137| 126962|       38175|              3.06|      3651|    26168|    20450|     21928|    67918|\n",
      "+---------------+----------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the `state` column\n",
    "us=us.drop(\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State_Code',\n",
       " 'Median_age',\n",
       " 'Male_Pop',\n",
       " 'Fem_Pop',\n",
       " 'Ttl_Pop',\n",
       " 'Foreign-born',\n",
       " 'Avg_Household_Size',\n",
       " 'Native_Pop',\n",
       " 'Asian_Pop',\n",
       " 'Black_Pop',\n",
       " 'Latino_Pop',\n",
       " 'White_Pop']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now write (and overwrite) transformed `US` dataset onto parquet file\n",
    "us.write.mode('overwrite').parquet(\"./data/us_cities_demographics.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I94 NON-IMMIGRATION DATA SET (CLEANING AND TRANSFORMATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read i94 non-immigration dataset\n",
    "i94_spark=spark.read.parquet(\"sas_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cicid',\n",
       " 'i94yr',\n",
       " 'i94mon',\n",
       " 'i94cit',\n",
       " 'i94res',\n",
       " 'i94port',\n",
       " 'arrdate',\n",
       " 'i94mode',\n",
       " 'i94addr',\n",
       " 'depdate',\n",
       " 'i94bir',\n",
       " 'i94visa',\n",
       " 'count',\n",
       " 'dtadfile',\n",
       " 'visapost',\n",
       " 'occup',\n",
       " 'entdepa',\n",
       " 'entdepd',\n",
       " 'entdepu',\n",
       " 'matflag',\n",
       " 'biryear',\n",
       " 'dtaddto',\n",
       " 'gender',\n",
       " 'insnum',\n",
       " 'airline',\n",
       " 'admnum',\n",
       " 'fltno',\n",
       " 'visatype']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "| 438.0|    LOS|20574.0|    1.0|20582.0|  40.0|    1.0|  1.0|     F|94953870030|\n",
      "| 438.0|    LOS|20574.0|    1.0|20591.0|  32.0|    1.0|  1.0|     F|94955622830|\n",
      "| 438.0|    LOS|20574.0|    1.0|20582.0|  29.0|    1.0|  1.0|     M|94956406530|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_spark.select(\"i94res\",\"i94port\",\"arrdate\",\"i94mode\",\"depdate\",\"i94bir\",\"i94visa\",\"count\" \\\n",
    "                  ,\"gender\",col(\"admnum\").cast(LongType())).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converted numbers longtype and integrtype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94_spark=i94_spark.select(col(\"i94res\").cast(IntegerType()),col(\"i94port\"),\n",
    "                           col(\"arrdate\").cast(IntegerType()), \\\n",
    "                           col(\"i94mode\").cast(IntegerType()),col(\"depdate\").cast(IntegerType()),\n",
    "                           col(\"i94bir\").cast(IntegerType()),col(\"i94visa\").cast(IntegerType()), \n",
    "                           col(\"count\").cast(IntegerType()), \\\n",
    "                              \"gender\",col(\"admnum\").cast(LongType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|   438|    LOS|  20574|      1|  20582|    40|      1|    1|     F|94953870030|\n",
      "|   438|    LOS|  20574|      1|  20591|    32|      1|    1|     F|94955622830|\n",
      "|   438|    LOS|  20574|      1|  20582|    29|      1|    1|     M|94956406530|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_spark.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicate rows on each dataset by comparing original total rows \n",
    "with .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096313, 3096302)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_spark.count(), i94_spark.dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3075579"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_spark.dropDuplicates(['admnum']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that 'admnum' may not be unique which we presummed.\n",
    "We will only drop duplicate rows instead of dropping duplicates by only `admnum` and let so we will have unique rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will drop duplicate rows and save it as final dataset for i94\n",
    "i94_spark=i94_spark.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "|   582|    XXX|  20557|   null|  20558|    34|      2|    1|  null|91904214530|\n",
      "|   209|    AGA|  20552|      1|   null|  null|      2|    1|     M|47842155333|\n",
      "|   209|    ATL|  20571|      1|   null|  null|      2|    1|     M|44537883633|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_spark.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save `i94_spark` dataframe to parquet file after we join `i94port` and `us` dataframes which you will see later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing cleaning tasks for i94 code lists and creating dimension tables\n",
    "\n",
    "The I94_SAS_Labels_Description.SAS file was used to create master i94 code lists by creating text files \n",
    "and then cleaning whitespaces and quotations; converting them to python lists. Then finally saving them as parquet files. These files will be used as master record attribute files because they do not frequently change.\n",
    ">Note: There were some manual data cleaning done by hand inside the text files before processing them. \n",
    "Any code description with words No/Collapsed/INVALID/ALL were manually removed from the text files. \n",
    "Smaller lists of codes were also created by hand such as i94mode and i94visa.\n",
    "Finally all master i94 code lists were written to parquets files. \n",
    "These parquet files will be used to join with `i94_spark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start processing the I9I94_SAS_Labels_Description.SAS to create master i94 code dimensions:\n",
    "\n",
    "'''\n",
    "/* I94MODE - There are missing values as well as not reported (9) */\n",
    "\t1 = 'Air'\n",
    "\t2 = 'Sea'\n",
    "\t3 = 'Land'\n",
    "\t9 = 'Not reported' ;\n",
    "'''\n",
    "# Create i94mode list\n",
    "i94mode_data =[[1,'Air'],[2,'Sea'],[3,'Land'],[9,'Not reported']]\n",
    "\n",
    "# Convert to spark dataframe\n",
    "i94mode=spark.createDataFrame(i94mode_data)\n",
    "\n",
    "# Create i94mode parquet file\n",
    "i94mode.write.mode(\"overwrite\").parquet('./data/i94mode.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read i94port text file\n",
    "i94port_df = pd.read_csv('./data/i94port.txt',sep='=',names=['id','port'])\n",
    "\n",
    "# Remove whitespaces and single quotes\n",
    "i94port_df['id']=i94port_df['id'].str.strip().str.replace(\"'\",'')\n",
    "\n",
    "# Create two columns from i94port string: port_city and port_addr\n",
    "# also remove whitespaces and single quotes\n",
    "i94port_df['port_city'], i94port_df['port_state']=i94port_df['port'].str.strip().str.replace(\"'\",'').str.strip().str.split(',',1).str\n",
    "\n",
    "# Remove more whitespace from port_addr\n",
    "i94port_df['port_state']=i94port_df['port_state'].str.strip()\n",
    "\n",
    "# Drop port column and keep the two new columns: port_city and port_addr\n",
    "i94port_df.drop(columns =['port'], inplace = True)\n",
    "\n",
    "# Convert pandas dataframe to list (objects which had single quotes removed automatically become string again with single quotes)\n",
    "i94port_data=i94port_df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert list to spark dataframe\n",
    "# Create a schema for the dataframe\n",
    "i94port_schema = StructType([\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('port_city', StringType(), True),\n",
    "    StructField('port_state', StringType(), True)\n",
    "])\n",
    "i94port=spark.createDataFrame(i94port_data, i94port_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parquet file\n",
    "i94port.write.mode('overwrite').parquet('./data/i94port.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read i94res text file\n",
    "i94res_df = pd.read_csv('./data/i94res_cit.txt',sep='=',names=['id','country'])\n",
    "# Remove whitespaces and single quotes\n",
    "i94res_df['country']=i94res_df['country'].str.replace(\"'\",'').str.strip()\n",
    "# Convert pandas dataframe to list (objects which had single quotes removed automatically become string again with single quotes)\n",
    "i94res_data=i94res_df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert list to spark dataframe\n",
    "# Create a schema for the dataframe\n",
    "i94res_schema = StructType([\n",
    "    StructField('id', StringType(), True),\n",
    "    StructField('country', StringType(), True)\n",
    "])\n",
    "i94res=spark.createDataFrame(i94res_data, i94res_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parquet file\n",
    "i94res.write.mode('overwrite').parquet('./data/i94res.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''/* I94VISA - Visa codes collapsed into three categories:\n",
    "   1 = Business\n",
    "   2 = Pleasure\n",
    "   3 = Student\n",
    "*/'''\n",
    "i94visa_data = [[1, 'Business'], [2, 'Pleasure'], [3, 'Student']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to spark dataframe\n",
    "i94visa=spark.createDataFrame(i94visa_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parquet file\n",
    "i94visa.write.mode('overwrite').parquet('./data/i94visa.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+\n",
      "|           City|State_Code|Median_age|Male_Pop|Fem_Pop|Ttl_Pop|Foreign-born|Avg_Household_Size|Native_Pop|Asian_Pop|Black_Pop|Latino_Pop|White_Pop|\n",
      "+---------------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+\n",
      "|Highlands Ranch|        CO|      39.6|   49186|  53281| 102467|        8827|              2.72|      1480|     5650|     1779|      8393|    94499|\n",
      "|           Kent|        WA|      33.4|   61825|  65137| 126962|       38175|              3.06|      3651|    26168|    20450|     21928|    67918|\n",
      "|        Madison|        WI|      30.7|  122596| 126360| 248956|       30090|              2.23|      2296|    23937|    20424|     19697|   204302|\n",
      "+---------------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i94res',\n",
       " 'i94port',\n",
       " 'arrdate',\n",
       " 'i94mode',\n",
       " 'depdate',\n",
       " 'i94bir',\n",
       " 'i94visa',\n",
       " 'count',\n",
       " 'gender',\n",
       " 'admnum']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096302"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add i94port city and state columns to i94 dataframe\n",
    "i94_spark.join(i94port, i94_spark.i94port==i94port.id, how='left').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above count matches original i94 cleaned dataset `i94_spark`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit i94_spark\n",
    "i94_spark=i94_spark.join(i94port, i94_spark.i94port==i94port.id, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---+---------+----------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum| id|port_city|port_state|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---+---------+----------+\n",
      "|   110|    BGM|  20550|      1|  20556|    36|      1|    1|     F|92847893530|BGM|   BANGOR|        ME|\n",
      "|   108|    BGM|  20569|      1|  20571|    43|      1|    1|     M|59234302533|BGM|   BANGOR|        ME|\n",
      "|   129|    BGM|  20559|      1|  20584|    67|      1|    1|     M|93553405030|BGM|   BANGOR|        ME|\n",
      "|   261|    BGM|  20568|      1|   null|     9|      1|    1|     M|94455571030|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM|  20564|      1|  20569|    30|      2|    1|     M|94033156330|BGM|   BANGOR|        ME|\n",
      "|   111|    BGM|  20563|      1|  20567|    56|      1|    1|     M|93951299930|BGM|   BANGOR|        ME|\n",
      "|   582|    BGM|  20563|      1|  20575|    57|      1|    1|     M|93924664230|BGM|   BANGOR|        ME|\n",
      "|   373|    BGM|  20547|      1|  20549|    55|      1|    1|     M|92692756930|BGM|   BANGOR|        ME|\n",
      "|   127|    BGM|  20571|      1|  20661|    27|      1|    1|     F|94670010530|BGM|   BANGOR|        ME|\n",
      "|   582|    BGM|  20566|      1|  20567|    42|      1|    1|     M|94251980230|BGM|   BANGOR|        ME|\n",
      "|   124|    BGM|  20547|      1|  20549|    38|      1|    1|     M|92692552430|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM|  20564|      1|  20569|    33|      2|    1|     M|94033775030|BGM|   BANGOR|        ME|\n",
      "|   108|    BGM|  20569|      1|  20571|    40|      1|    1|     M|94510578330|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM|  20565|      1|  20581|    34|      2|    1|     F|56546213233|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM|  20547|      1|  20687|    69|      1|    1|     M|92664011030|BGM|   BANGOR|        ME|\n",
      "|   158|    BGM|  20547|      1|  20550|    15|      2|    1|     F|92609680230|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM|  20556|      1|  20557|    63|      1|    1|     M|93334238330|BGM|   BANGOR|        ME|\n",
      "|   112|    BGM|  20566|      1|  20581|    45|      1|    1|     M|94264768730|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM|  20547|      1|  20678|    62|      2|    1|     M|92648354430|BGM|   BANGOR|        ME|\n",
      "|   135|    BGM|  20564|      1|  20569|    36|      2|    1|     M|94033624830|BGM|   BANGOR|        ME|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop `id` column\n",
    "i94_spark=i94_spark.drop(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i94res',\n",
       " 'i94port',\n",
       " 'arrdate',\n",
       " 'i94mode',\n",
       " 'depdate',\n",
       " 'i94bir',\n",
       " 'i94visa',\n",
       " 'count',\n",
       " 'gender',\n",
       " 'admnum',\n",
       " 'port_city',\n",
       " 'port_state']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State_Code',\n",
       " 'Median_age',\n",
       " 'Male_Pop',\n",
       " 'Fem_Pop',\n",
       " 'Ttl_Pop',\n",
       " 'Foreign-born',\n",
       " 'Avg_Household_Size',\n",
       " 'Native_Pop',\n",
       " 'Asian_Pop',\n",
       " 'Black_Pop',\n",
       " 'Latino_Pop',\n",
       " 'White_Pop']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join US with i94_spark to get fact table `i94non_immigrant_port_entry`\n",
    "# NOTE: We use left join againt city records which may cause null values because\n",
    "# we may not currently have demographic stats on all U.S. ports of entry\n",
    "i94non_immigrant_port_entry=i94_spark.join(us, (upper(i94_spark.port_city)==upper(us.City)) & \\\n",
    "                                           (upper(i94_spark.port_state)==upper(us.State_Code)), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3096302"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94non_immigrant_port_entry.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i94res',\n",
       " 'i94port',\n",
       " 'arrdate',\n",
       " 'i94mode',\n",
       " 'depdate',\n",
       " 'i94bir',\n",
       " 'i94visa',\n",
       " 'count',\n",
       " 'gender',\n",
       " 'admnum',\n",
       " 'port_city',\n",
       " 'port_state',\n",
       " 'City',\n",
       " 'State_Code',\n",
       " 'Median_age',\n",
       " 'Male_Pop',\n",
       " 'Fem_Pop',\n",
       " 'Ttl_Pop',\n",
       " 'Foreign-born',\n",
       " 'Avg_Household_Size',\n",
       " 'Native_Pop',\n",
       " 'Asian_Pop',\n",
       " 'Black_Pop',\n",
       " 'Latino_Pop',\n",
       " 'White_Pop']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94non_immigrant_port_entry.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop City and State_Code\n",
    "i94non_immigrant_port_entry=i94non_immigrant_port_entry.drop(\"City\",\"State_Code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum|port_city|port_state|Median_age|Male_Pop|Fem_Pop|Ttl_Pop|Foreign-born|Avg_Household_Size|Native_Pop|Asian_Pop|Black_Pop|Latino_Pop|White_Pop|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+\n",
      "|   103|    NEC|  20556|      3|  20557|    51|      2|    1|     F|  788711085|    NECHE|        ND|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   112|    NEC|  20573|      3|  20575|    32|      2|    1|     F|59477349333|    NECHE|        ND|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   245|    LEW|  20574|      3|  20576|    21|      2|    1|     F|94960311530| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   245|    LEW|  20546|      3|   null|    27|      3|    1|     F|71136033030| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   263|    LEW|  20559|      3|  20561|    38|      2|    1|  null|93151263430| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   514|    LEW|  20574|      3|  20596|    38|      2|    1|     F|94972653530| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   112|    LEW|  20560|      3|   null|    48|      2|    1|     M|17269695927| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   514|    LEW|  20552|      3|  20554|    52|      2|    1|     F|  745535185| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   260|    LEW|  20559|      3|  20561|    53|      2|    1|     F|80354257630| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   206|    LEW|  20549|      3|  20554|    20|      2|    1|     F|91281323030| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   213|    LEW|  20573|      3|  20575|    31|      2|    1|     F|79211218230| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   274|    LEW|  20573|      3|  20576|    31|      2|    1|     M|94859874130| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   213|    LEW|  20573|      3|  20576|    34|      2|    1|     M|94831519930| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   276|    LEW|  20560|      3|  20574|    35|      3|    1|     F|77790902930| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   111|    LEW|  20570|      3|  20576|    47|      2|    1|     M|59315035133| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   213|    LEW|  20571|      3|  20622|    47|      2|    1|     F|  751570585| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   135|    LEW|  20558|      3|  20560|    52|      2|    1|     M|55840487133| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   135|    LEW|  20560|      3|  20561|    53|      2|    1|     M|54209393433| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   514|    LEW|  20574|      3|  20575|    56|      2|    1|     F|80374948630| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "|   111|    LEW|  20562|      3|  20565|    57|      1|    1|     M|56399954533| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94non_immigrant_port_entry.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the i94date dimension from the i94non_immigrant_port_entry dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SAS arrival date to datetime format\n",
    "get_date = udf(lambda x: (dt.datetime(1960, 1, 1).date() + dt.timedelta(x)).isoformat() if x else None)\n",
    "i94non_immigrant_port_entry = i94non_immigrant_port_entry.withColumn(\"arrival_date\", get_date(i94non_immigrant_port_entry.arrdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+------------+\n",
      "|i94res|i94port|arrdate|i94mode|depdate|i94bir|i94visa|count|gender|     admnum|port_city|port_state|Median_age|Male_Pop|Fem_Pop|Ttl_Pop|Foreign-born|Avg_Household_Size|Native_Pop|Asian_Pop|Black_Pop|Latino_Pop|White_Pop|arrival_date|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+------------+\n",
      "|   103|    NEC|  20556|      3|  20557|    51|      2|    1|     F|  788711085|    NECHE|        ND|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|  2016-04-12|\n",
      "|   112|    NEC|  20573|      3|  20575|    32|      2|    1|     F|59477349333|    NECHE|        ND|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|  2016-04-29|\n",
      "|   245|    LEW|  20574|      3|  20576|    21|      2|    1|     F|94960311530| LEWISTON|        NY|      null|    null|   null|   null|        null|              null|      null|     null|     null|      null|     null|  2016-04-30|\n",
      "+------+-------+-------+-------+-------+------+-------+-----+------+-----------+---------+----------+----------+--------+-------+-------+------------+------------------+----------+---------+---------+----------+---------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94non_immigrant_port_entry.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "i94date=i94non_immigrant_port_entry.select(col('arrdate').alias('arrival_sasdate'),\n",
    "                                   col('arrival_date').alias('arrival_iso_date'),\n",
    "                                   date_format('arrival_date','M').alias('arrival_month'),\n",
    "                                   date_format('arrival_date','E').alias('arrival_dayofweek'), \n",
    "                                   date_format('arrival_date', 'y').alias('arrival_year'), \n",
    "                                   date_format('arrival_date', 'd').alias('arrival_day'),\n",
    "                                  date_format('arrival_date','w').alias('arrival_weekofyear')).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop arrival_date column from the i94non_immigrant_port_entry dataframe and finally save it to parquet file \n",
    "i94non_immigrant_port_entry.drop('arrival_date').write.mode(\"overwrite\").parquet('./data/i94non_immigrant_port_entry.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94date.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+-------------+-----------------+------------+-----------+------------------+\n",
      "|arrival_sasdate|arrival_iso_date|arrival_month|arrival_dayofweek|arrival_year|arrival_day|arrival_weekofyear|\n",
      "+---------------+----------------+-------------+-----------------+------------+-----------+------------------+\n",
      "|          20562|      2016-04-18|            4|              Mon|        2016|         18|                17|\n",
      "|          20554|      2016-04-10|            4|              Sun|        2016|         10|                16|\n",
      "|          20556|      2016-04-12|            4|              Tue|        2016|         12|                16|\n",
      "|          20548|      2016-04-04|            4|              Mon|        2016|          4|                15|\n",
      "|          20553|      2016-04-09|            4|              Sat|        2016|          9|                15|\n",
      "+---------------+----------------+-------------+-----------------+------------+-----------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94date.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary sql table\n",
    "i94date.createOrReplaceTempView(\"i94date_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add seasons to i94 date dimension table\n",
    "i94date_season=spark.sql('''select arrival_sasdate,\n",
    "                         arrival_iso_date,\n",
    "                         arrival_month,\n",
    "                         arrival_dayofweek,\n",
    "                         arrival_year,\n",
    "                         arrival_day,\n",
    "                         arrival_weekofyear,\n",
    "                         CASE WHEN arrival_month IN (12, 1, 2) THEN 'winter' \n",
    "                                WHEN arrival_month IN (3, 4, 5) THEN 'spring' \n",
    "                                WHEN arrival_month IN (6, 7, 8) THEN 'summer' \n",
    "                                ELSE 'autumn' \n",
    "                         END AS date_season from i94date_table''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------------+-------------+-----------------+------------+-----------+------------------+-----------+\n",
      "|arrival_sasdate|arrival_iso_date|arrival_month|arrival_dayofweek|arrival_year|arrival_day|arrival_weekofyear|date_season|\n",
      "+---------------+----------------+-------------+-----------------+------------+-----------+------------------+-----------+\n",
      "|          20562|      2016-04-18|            4|              Mon|        2016|         18|                17|     spring|\n",
      "|          20554|      2016-04-10|            4|              Sun|        2016|         10|                16|     spring|\n",
      "|          20556|      2016-04-12|            4|              Tue|        2016|         12|                16|     spring|\n",
      "+---------------+----------------+-------------+-----------------+------------+-----------+------------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94date_season.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save i94date dimension to parquet file partitioned by year and month:\n",
    "i94date_season.write.mode(\"overwrite\").partitionBy(\"arrival_year\", \"arrival_month\").parquet('./data/i94date.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "Using the dimensional tables saved as parquet files we can implement them on any columnar database in Star Schema model.\n",
    "Star Schema model was chosen because it will be easier for Data Analysts and Data Scientists\n",
    "to understand and apply queries with best performance outcomes and flexibility.\n",
    "\n",
    "\n",
    "#### U.S. Immigration and U.S. Ports Cities Demographics Data Model\n",
    "<img src=\"./i94star_schema2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Install the packages:\n",
    "    - pandas\n",
    "    - datetime\n",
    "    - pyspark.sql -> SparkSession -> \"org.apache.hadoop:hadoop-aws:2.7.0\"\n",
    "    - pyspark.sql.functions -> first, upper, col, udf, date_format, expr\n",
    "    - pyspark.sql.types -> StructField, StructType, StringType, LongType, IntegerType\n",
    "\n",
    "\n",
    "2. Create the dimensions (i94port, i94visa, i94res, i94mode) from `i94_SAS_Labels_Descriptions.SAS` file. *NOTE: Once they're created it does not have to be included in future Data Pipeline schedules because these are essentially master records which do not frequently get added or changed on the dimension tables.\n",
    "\n",
    "3. Read US Cities Demo dataset file to form `us_spark` dataframe\n",
    "\n",
    "4. Create 'us_race_cnt' from `us_spark`\n",
    "\n",
    "5. Drop columns we don't need and drop duplicate rows from `us_spark`\n",
    "\n",
    "6. Join `us_spark` with us_race_cnt to form `US` data set\n",
    "\n",
    "7. Change `state code` column name to `state_code` and other similar problems to avoid parquet complications\n",
    "\n",
    "8. Drop the `state` column\n",
    "\n",
    "9. Write (and overwrite) transformed `US` dataset onto parquet file\n",
    "\n",
    "10. Read i94 non-immigration dataset to form `i94_spark` dataframe\n",
    "\n",
    "11. Convert numbers to longtype and integertype\n",
    "\n",
    "12. Drop duplicate rows\n",
    "\n",
    "13. Read i94port dimension parquet file so we can use it to join with `i94_spark`. This will add i94port city and state columns to i94_spark dataframe\n",
    "\n",
    "14. Drop `id` column from i94_spark dataframe\n",
    "\n",
    "15. Join US with i94_spark to get fact table `i94non_immigrant_port_entry`\n",
    "\n",
    "18. Add iso date format column `arrival_date` inside the `i94non_immigrant_port_entry` dataframe by using custom function.\n",
    "\n",
    "17. Create `time` dimension from `i94non_immigrant_port_entry` and save to parquet file.\n",
    "\n",
    "18. Drop `arrival_date` column from `i94non_immigrant_port_entry` and save it to parquet file.\n",
    "\n",
    "19. Add seasons to i94date_seasons dataframe.\n",
    "\n",
    "20. Save i94date_seasons to parquet file partitioned by year and month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The data pipeline is built inside the `ETL.py` file included with this Capstone Project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed reading data file.\n",
      "Transformation went perfect.\n",
      "Passed reading data file.\n",
      "Transformation went perfect.\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "\n",
    "if us_spark.count() > 0:\n",
    "    print('Passed reading data file.')\n",
    "else:\n",
    "    print('Seems to be nothing in file!')\n",
    "\n",
    "if us.count() == us_race_cnt.count():\n",
    "    print('Transformation went perfect.')\n",
    "else:\n",
    "    print('Inconsistant data between both dataframes!')\n",
    "\n",
    "if i94_spark.count() > 0:\n",
    "    print('Passed reading data file.')\n",
    "else:\n",
    "    print('Seems to be nothing in file!')\n",
    "    \n",
    "if i94_spark.count() == i94non_immigrant_port_entry.count():\n",
    "    print('Transformation went perfect.')\n",
    "else:\n",
    "    print('Inconsistant data between both dataframes!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "'''\n",
    "i94date\n",
    "---------------\n",
    "arrival_sasdate int PK\n",
    "    > Non-immigrant arrival date in the USA (SAS date numeric field) from `arrdate` i94 non-immigration data\n",
    "arrival_isodate date\n",
    "    > converted to iso date format (YYYY-MM-DD) from arrival_sasdate\n",
    "arrival_month int\n",
    "arrival_day int\n",
    "arrival_year int\n",
    "arrival_week int\n",
    "    > week of year\n",
    "arrival_season string\n",
    "    > winter, spring, summer or autumn seasons\n",
    "\n",
    "i94port\n",
    "--------------\n",
    "id string PK\n",
    "    > i94 port 3 character code of destination USA city\n",
    "city string\n",
    "state string\n",
    "\n",
    "i94visa\n",
    "--------------\n",
    "id int PK\n",
    "    > i94 visa code number stating reason for immigration from i94 non-immigration data\n",
    "reason string\n",
    "\n",
    "i94res\n",
    "--------------\n",
    "id int PK\n",
    "    > i94 3 digit code of nationality from i94 non-immigration data\n",
    "country string\n",
    "\n",
    "i94mode\n",
    "--------------\n",
    "id int PK\n",
    "    > i94 1 digit mode (plane, boat, etc) of travel code from i94 non-immigration data\n",
    "transport string\n",
    "\n",
    "i94non_immigrant_port_entry\n",
    "-----------------------------------\n",
    "admnum int PK\n",
    "    > Admission Number from i94 non-immigration data\n",
    "arrdate int FK >- i94date.arrival_sasdate\n",
    "    > arrival date in the USA (SAS date numeric field) from i94 non-immigration data\n",
    "depdate int\n",
    "    > Departure Date from the USA. It is a SAS date numeric field from i94 non-immigration data\n",
    "port_id string FK >- i94port.id\n",
    "    > 3 character code of destination USA city from i94 non-immigration data\n",
    "visa_id int FK >- i94visa.id\n",
    "    > reason for immigration from i94 non-immigration data\n",
    "res_id int FK >- i94res.id\n",
    "    > 3 digit code of nationality from i94 non-immigration data\n",
    "mode_id int FK >- i94mode.id\n",
    "    > 1 digit mode (plane, boat, etc) of travel code from i94 non-immigration data\n",
    "age int\n",
    "    > Age of non-immigrant in years from i94 non-immigration data\n",
    "gender string\n",
    "    > Non-immigrant sex from i94 non-immigration data\n",
    "cnt_of_one int\n",
    "    > count of one per row used for statistical metrics from i94 non-immigration data\n",
    "median_age float\n",
    "    > Median age of population in city and state from US cities demographics data\n",
    "male_pop int\n",
    "    > Male population of city and state from US cities demographics data\n",
    "female_pop int\n",
    "    > Female population of city and state from US cities demographics data\n",
    "ttl_pop int\n",
    "    > Total population of city and state from US cities demographics data\n",
    "foreign_born_pop int\n",
    "    > Foreign born population of city and state from US cities demographics data\n",
    "avg_household_size float\n",
    "    > Average household size of city and state from US cities demographics data\n",
    "american_indian_alaskan_native_pop int\n",
    "    > Aerican Indian population of city and state from US cities demographics data\n",
    "asian_pop int\n",
    "    > Asian population of city and state from US cities demographics data\n",
    "black_african_american_pop int\n",
    "    > Black population of city and state from US cities demographics data\n",
    "hispanic_pop int\n",
    "    > Hispanic population of city and state from US cities demographics data\n",
    "white_pop int\n",
    "    > White population of city and state from US cities demographics data\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    ">Because we are dealing with big data and cloud technologies for solutions it made economical sense to use opensource Apache PySpark and Python tools that can be easily ported over to cloud solution such as AWS.\n",
    "* Propose how often the data should be updated and why.\n",
    "> Dimenstion tables only have to be updated when a new category is created by I94. However, the I94 non-immigrant port of entry data along with the time dimension table (i94date) can be updated every month. The US Cities Demographics data is updated every ten years according to https://www.usa.gov/statistics. So, the new US Cities Demographics data set maybe coming after year 2020. And may need updating after one year or two years as of 2019.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " >Deploy this Spark solution on a cluster using AWS (EMR cluster) and use S3 for data and parquet file storage. AWS will easily scale when data increases by 100x\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " >Use Apache Airflow to schedule queries.\n",
    " * The database needed to be accessed by 100+ people.\n",
    " >The saved parquet files can be bulk copied over to AWS Redshift cluster where it can scale big data requirements and has 'massively parallel' and 'limitless concurrency' for thousands of concurrent queries executed by users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
